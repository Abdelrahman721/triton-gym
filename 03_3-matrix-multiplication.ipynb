{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e84b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton\n",
    "import triton.language as tl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d2f52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autotune_configs():\n",
    "    return [\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=3,\n",
    "                      num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5,\n",
    "                      num_warps=2),\n",
    "        triton.Config({'BLOCK_SIZE_M': 32, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 32, 'GROUP_SIZE_M': 8}, num_stages=5,\n",
    "                      num_warps=2),\n",
    "        # Good config for fp8 inputs.\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=3,\n",
    "                      num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=3,\n",
    "                      num_warps=8),\n",
    "        triton.Config({'BLOCK_SIZE_M': 256, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 256, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 128, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 64, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 64, 'BLOCK_SIZE_N': 128, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4),\n",
    "        triton.Config({'BLOCK_SIZE_M': 128, 'BLOCK_SIZE_N': 32, 'BLOCK_SIZE_K': 64, 'GROUP_SIZE_M': 8}, num_stages=4,\n",
    "                      num_warps=4)\n",
    "    ]\n",
    "\n",
    "\n",
    "@triton.autotune(\n",
    "    configs=get_autotune_configs(),\n",
    "    key= ['M', 'N', 'K']\n",
    ")\n",
    "@triton.jit\n",
    "def mm_kernel(a_ptr, b_ptr, c_ptr,\n",
    "              M, N, K,\n",
    "              am_stride, ak_stride,\n",
    "              bk_stride, bn_stride,\n",
    "              cm_stride, cn_stride,\n",
    "              BLOCK_SIZE_M: tl.constexpr,\n",
    "              BLOCK_SIZE_N: tl.constexpr,\n",
    "              BLOCK_SIZE_K: tl.constexpr,\n",
    "              M_GROUP_SIZE: tl.constexpr,\n",
    "              ):\n",
    "    pid          = tl.program_id(0)\n",
    "    num_programs = tl.num_programs(0)\n",
    "\n",
    "    n_blocks          = tl.cdiv(N, BLOCK_SIZE_N)\n",
    "    m_blocks          = tl.cdiv(M, BLOCK_SIZE_M)\n",
    "    num_pid_per_group = M_GROUP_SIZE * n_blocks\n",
    "    grp_idx           = pid // num_pid_per_group\n",
    "    m_group_size      = min(m_blocks - grp_idx * M_GROUP_SIZE, M_GROUP_SIZE)\n",
    "\n",
    "    group_m = grd_idx * M_GROUP_SIZE\n",
    "    pid_m   = group_m + BLOCK_SIZE_M * (pid % m_group_size)\n",
    "    pid_n   = BLOCK_SIZE_N * ((pid % m_group_size) // m_group_size)\n",
    "\n",
    "    am_offsets = pid_m + tl.arange(0, BLOCK_SIZE_M)\n",
    "    bn_offsets = pid_n + tl.arange(0, BLOCK_SIZE_N)\n",
    "    k_offsets  = tl.arange(0, BLOCK_SIZE_K)\n",
    "\n",
    "    a_ptrs = a_ptr + (am_offsets * am_stride + k_offsets * ak_stride)\n",
    "    b_ptrs = b_ptr + (k_offsets * bk_stride + bn_offsets * bn_stride)\n",
    "\n",
    "    accumulator = tl.zeros((BLOCK_SIZE_M, BLOCK_SIZE_N), dtype=tl.float32)\n",
    "    for k in tl.range(0, K, BLOCK_SIZE_K):\n",
    "        a_block = tl.load(a_ptrs, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
